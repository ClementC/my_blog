{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlÃ² ðŸ‡­ðŸ‡¹\n",
    "\n",
    "A dream many in the NLP (_Natural Language Processing_) world share is to unlock deeper insights and quantify well-known phenomena in literature by applying algorithms to lengthy texts ðŸ¤–ðŸ“–. Take for instance [this fascinating study](https://aclanthology.org/2022.findings-acl.81.pdf), which dives into the creation of numerical representations or 'embeddings' of fictional characters. It's a game-changer! We can now detect shared traits among characters from different stories.<br>\n",
    "It also leaves me pondering if we could play around with a form of \"character algebra\", something akin to the [\"word algebra\"](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/) in `word2vec`. Could we have something like `Sherlock Holmes - Watson + Hastings â‰ƒ Hercule Poirot` or `Don Quixote - Sancho Panza + Little John â‰ƒ Robin Hood`?\n",
    "<img src=\"/images/word_algebra.png\" title='word2vec allowed to experiment with \"word algebra\".' style=\"width:600px\"/>\n",
    "\n",
    "When we're crafting machine learning models, a question that's always at the back of our minds is whether packing in more data would supercharge performance. It's a head-scratcher that's traditionally sorted out through good old trial and error. However, a squad from Microsoft Research has come up with some [seriously encouraging initial findings](https://www.microsoft.com/en-us/research/blog/measuring-dataset-similarity-using-optimal-transport) on calculating distances between datasets. This could be the silver bullet we've been waiting for to decide which dataset to use for training data augmentation. The blog post is chock-full of interactive visuals that make understanding the approach a breeze.<br>\n",
    "The metric they're using, known as the [Wasserstein distance](https://en.wikipedia.org/wiki/Wasserstein_metric), can be traced back to a far more \"down-to-earth\" problem posed in 1781 by French mathematician Gaspard Monge: How can you shift a pile of rubble from A to B, spending the least amount of energy?\n",
    "\n",
    "Finally, let's wrap up with a [methodological paper](https://arxiv.org/pdf/2103.03098.pdf) on best practices for evaluating machine learning models, particularly when you're out to show you've got a leg up on the current state-of-the-art. As there are numerous sources of variation (choice of dataset, splitting into train/test, random seeds, hyperparameter tuning...) a classifier's performance can be considered a random variable. Therefore, it's crucial to sample from these sources of randomness ðŸŽ² as much as possible to provide convincing proof that one method is superior to another.<br>\n",
    "The key takeaways from the paper are summed up [here in a Twitter thread](https://twitter.com/GaelVaroquaux/status/1367839174469029899) by GaÃ«l Varoquaux, one of the co-founders of scikit-learn and co-author of the paper.\n",
    "\n",
    "Wishing you a week filled with insightful reads! ðŸ“š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
