{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan :\n",
    "- intro sur l'article + contexte\n",
    "- explications / démo de l'implem : alpha, multi classe\n",
    "- pointeurs vers stats bayésiennes\n",
    "- explications pour l'extension multiclasse\n",
    "- lien vers implem\n",
    "\n",
    "Trouver titre :\n",
    "- \"Getting confidence in classification evaluation metrics\"\n",
    "\n",
    "\n",
    "TODO / Check:\n",
    "- [ ] autre article : http://oliviercaelen.be/doc/confMatrixBayes_AMAI.pdf\n",
    "- \"multiclass problem\"?\n",
    "- vérifier screenshots (cohérence nombre digits...), inclure la cellule de code ?\n",
    "- lien sklearn classification report\n",
    "- lien breast cancer dataset\n",
    "- regarder les guidelines pour les PR dans sklearn ; sinon soumettre une implem à https://sklearn-evaluation.ploomber.io/ ?\n",
    "- implem : donner la possibilité de sortir les samples ?\n",
    "- add a legend for the width of the confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're tasked with a new classification problem: with the data you're given, you train a model, and get some evaluation metrics (precision, recall, F1 score...). Yay! You can call it a day!\n",
    "\n",
    "Right?... Right?\n",
    "\n",
    "But how confident are you in the numbers you have? Would they change, say if you retrained your model, or if your dataset was split differently, or had slightly more or less samples, or had a slightly different class balance? By how much would they move?\n",
    "\n",
    "Or say you have several models with a similar performance, but trained on different subsets of the data of varying size. Which one would you choose?\n",
    "\n",
    "We intuitively feel that the size of the testing set plays a large part here. In a similar way you would probably pick the restaurant noted 4.2 ⭐️ on 500+ ratings over the one noted 4.6 ⭐️ on 7 ratings.\n",
    "\n",
    "So, how can we be confident in the performance of the model we just trained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting confidence in classification evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few weeks ago I stumbled upon the paper __[\"A Probabilistic Interpretation of Precision, Recall and F-Score, with Implication for Evaluation\"](https://scholar.google.fr/scholar?q=A+Probabilistic+Interpretation+of+Precision,+Recall+and+F-Score,+with+Implication+for+Evaluation&hl=fr&as_sdt=0&as_vis=1&oi=scholart)__ (Cyril Goutte & Eric Gaussier, 2005). After quickly reading the summary, I got quite excited, because it presents a principled way to compute confidence intervals for evaluation metrics for classification such as precision, recall, or f-score.\n",
    "\n",
    "Until then, I knew only of two ways to compute confidence intervals for those metrics on a scikit-learn-style classification report or on a precision-recall curve.\n",
    "The first one is recomputing the full learning-and-predicting loop say several dozens times to get decent distributions for the evaluation metrics of interest, which can be very costly.\n",
    "The second one is by computing bootstrap estimates, which is very fast, but felt somewhat unsatisfactory, and is in fact not recommended (see __[\"Statistical inference in retrieval effectiveness evaluation](https://scholar.google.fr/scholar?hl=fr&as_sdt=0%2C5&q=Statistical+inference+in+retrieval+effectiveness+evaluation&btnG=)__ (Savoy, 1997), cited in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper introduces:\n",
    "- a principled, probabilistic formalism for obtaining posterior distributions on evaluation metrics for binary classification problems;\n",
    "- a framework to compare the performance of several classifiers on different datasets of the same source;\n",
    "- a refined framework to compare the performance of two classifiers on the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I eagerly read the paper, wanting to know more about the developed formalism, and to see if it would be easy to implement it in Python. I'm indeed regularly using the output of the scikit-learn classification report and sometimes meet questions by colleagues about the confidence we can get in some results based on small data. Answers are usually uneasy variations of \"we cannot be very confident until we have more data\".\n",
    "\n",
    "So I'm happy to say that the paper is very clear and readable, and that I quickly implemented a Python function derived from the __[famous scikit-learn classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.classification_report)__, and then extended it to multiclass problems. I can know report full distributions instead of point estimates, and so can you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation and demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the result of the function on the __[\"breast cancer\" dataset]()__, a binary problem, with a linear SVC:\n",
    "\n",
    "<img src=\"/figures/evaluation_metrics_with_confidence_binary.png\" title=\"Classification report with confidence intervals.\" style=\"width:600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the result on the __[\"digits\" dataset]()__, a 10-class problem, with a linear SVC:\n",
    "\n",
    "<img src=\"/figures/evaluation_metrics_with_confidence_10_classes.png\" title=\"Classification report with confidence intervals for a 10-class problem.\" style=\"width:600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass a parameter `alpha` to change the width of the confidence interval (95% by default, here 90%):\n",
    "\n",
    "<img src=\"/figures/evaluation_metrics_with_confidence_binary_alpha_90.png\" title=\"Classification report with confidence intervals.\" style=\"width:600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also visualize this with boxplots:\n",
    "\n",
    "<img src=\"/figures/10_classes_performance_boxplots.png\" title=\"Visualizing the classification report with boxplots.\" style=\"width:600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//// En fait pas certain qu'il faut ajouter ça, ça rend l'article hyper dense\n",
    "\n",
    "But wait, there's more! Since you can simulate a big number of classifier performance metrics, you can also visualize the confidence interval on more complicated stuff, such as the ROC curve or the precision-recall plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explications sur le principe :\n",
    "- dans un cas binaire, la précision et le rappel peuvent être naturellement modélisées par un processus binomial\n",
    "- priors naturels : loi Beta ; comme c'est un prior conjugué, on peut directement récupérer des intervalles de confiance sur p et r\n",
    "- pour f1 plus compliqué, mais je le fais par simulation : sample des distributions posterior de p et r, calcul des samples de f1, puis métriques sur la distribution obtenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explications multiclasse :\n",
    "- schéma pour montrer comment on passe de l'un à l'autre\n",
    "- est-ce que c'est vraiment directement du binaire ? pas besoin de modifier le formalisme ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
