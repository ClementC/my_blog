{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kú àárọ̀ 🇧🇯\n",
    "\n",
    "The realm of image generation is advancing at breakneck speed, with groundbreaking leaps happening every week 🚀. Dmitrii Tochilkin, a former researcher at Google and Russia's Yandex 🇷🇺, is pushing boundaries by marrying AI and art.<br>\n",
    "In his recent Twitter post, [\"A Year\"](https://twitter.com/cut_pow/status/1576748595109593088), Tochilkin gives us a glimpse into his newest venture, harnessing the Stable Diffusion algorithm. The steps to crafting this video are brilliantly explained in a follow-up thread, compiled [here](https://threadreaderapp.com/thread/1576748595109593088.html).<br>\n",
    "He first creates an image using Stable Diffusion, then employs another algorithm to estimate a \"depth map\" 🗺, effectively turning the image into a 3D scene. By shifting the viewpoint, he creates the illusion of camera movement, takes a snapshot, and fills in the blanks using Stable Diffusion. This process gives him a single frame for his film 🎞, and it's all about rinse and repeat from there, somewhat like stop-motion.<br>\n",
    "The end result? A dreamy, poetic, and slightly blurry masterpiece 💭.\n",
    "<img src=\"/images/making_movies_with_AI.gif\" title='Making dream-like movies with AI.' style=\"width:600px\"/>\n",
    "\n",
    "Statistical articles usually carry a measure of uncertainty for model evaluation metrics, a practice surprisingly less common in machine learning papers. But this is crucial to determine if one model truly excels over another.<br> Fortunately, there's a slew of methods, some quite simple, to rectify this blind spot. Sebastian Raschka dives into several in this [comprehensive blog post](https://sebastianraschka.com/blog/2022/confidence-intervals-for-ml.html) (covering normal approximation, bootstrap, re-seeding).<br>\n",
    "Fun fact: Sebastian also wrote [several books](https://sebastianraschka.com/books/) on Python machine learning 📚🐍.\n",
    "\n",
    "Data scientists eager to adopt solid software engineering practices often find themselves grappling with version control tools (especially Git) when it comes to Jupyter notebooks. That's because notebooks store not just code, but results and metadata (execution order, state...), which aren't exactly version-control-friendly.<br>\n",
    "The go-to solution so far has been to automate notebook output cleanup before archiving (usually via Git pre-commit hooks). However, open-source tools like nbdev2 are gaining traction. [This blog post](https://www.fast.ai/posts/2022-08-25-jupyter-git.html) showcases how it can be harnessed for meaningful diffs.<br>\n",
    "Brought to life by fast.ai, a non-profit research group founded in 2016 by Jeremy Howard and Rachel Thomas (see [⚡️Trendbreak #10⚡️](https://clementc.github.io/blog/2022/01/07/trendbreak_10/)) and known for their [top-tier free deep learning courses](https://course.fast.ai/) 🎓, nbdev2 is an exciting development.\n",
    "<img src=\"/images/nice_notebook_diffs.png\" title='Get nice notebook diffs with nbdev2.' style=\"width:600px\"/>\n",
    "\n",
    "Here's to a great read! 🍂☕️📘"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
